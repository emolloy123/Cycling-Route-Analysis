{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b75b357",
   "metadata": {},
   "source": [
    "# COMP 47670 - A2 Task 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7731a8da",
   "metadata": {},
   "source": [
    "Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af294179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, requests, urllib\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "import bs4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169f5d6d",
   "metadata": {},
   "source": [
    "Create directory for raw data storage, if it does not already exist:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08ce16df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_raw = Path(\"raw\")\n",
    "dir_raw.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1059c833",
   "metadata": {},
   "source": [
    "Download homepage using BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e800aca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_prefix = 'http://mlg.ucd.ie/modules/python/EVdata/'\n",
    "response = urllib.request.urlopen(url_prefix)\n",
    "page_soup = bs4.BeautifulSoup(response,\"html.parser\")\n",
    "response.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9000373",
   "metadata": {},
   "source": [
    "Search all \"a\" tags in the body to compile list of routes and their corresponding html pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34103380",
   "metadata": {},
   "outputs": [],
   "source": [
    "atags = page_soup.body.ul.find_all(\"a\")\n",
    "route_pages = []\n",
    "for a in atags:\n",
    "    if a.has_attr('href'):\n",
    "        route_pages.append(a['href'])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867fc878",
   "metadata": {},
   "source": [
    "Download the gpx file from each html page into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25f25c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_names = {}\n",
    "\n",
    "for route in route_pages:\n",
    "    #define endpoint for specific route\n",
    "    endpoint = url_prefix+route\n",
    "    #define key to be used in route_files\n",
    "    key = route.split(\".\")[0]\n",
    "    #open url for this route\n",
    "    response = urllib.request.urlopen(endpoint)\n",
    "    #beautify this page\n",
    "    page_soup = bs4.BeautifulSoup(response,\"html.parser\")\n",
    "    response.close()\n",
    "    #save text name of route\n",
    "    value = page_soup.h1.text\n",
    "    #save to dictionary\n",
    "    route_names[key] = value\n",
    "    #get gpx file name\n",
    "    gpx_file = page_soup.a['href']\n",
    "    #download this file to raw directory\n",
    "    out_path = dir_raw / (key+'.gpx')\n",
    "    url = url_prefix+gpx_file\n",
    "    urllib.request.urlretrieve(url, filename=out_path, reporthook=None, data=None)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6851d46a",
   "metadata": {},
   "source": [
    "Output route key value pairs to json as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acad5892",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('route_names.json', 'w') as fp:\n",
    "    json.dump(route_names, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
